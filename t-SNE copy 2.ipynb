{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe64b3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0       1       2       3       4       5       6       \\\n",
      "CellType                                                                      \n",
      "ILC2.SI                1.79    1.29    0.44    1.76    1.43    1.76    0.44   \n",
      "ILC3.NKp46-CCR6-.SI    1.67    3.87    2.49    0.95    0.15    0.57    1.36   \n",
      "ILC3.NKp46+.SI         0.75    0.23    0.23    0.23    2.14    0.23    0.23   \n",
      "ILC3.CCR6+.SI          1.21    0.15    0.95    0.15    0.15    0.95    1.41   \n",
      "NK.27+11b-.BM          0.82    1.46    0.20    1.72    0.20    1.46    0.82   \n",
      "\n",
      "                     7       8       9       ...  512585  512586  512587  \\\n",
      "CellType                                     ...                           \n",
      "ILC2.SI                0.10    1.29    1.79  ...   15.72    6.77    7.65   \n",
      "ILC3.NKp46-CCR6-.SI    3.98    3.14    1.36  ...   11.72    8.04    1.93   \n",
      "ILC3.NKp46+.SI         0.23    0.75    0.75  ...   16.99    8.56    7.52   \n",
      "ILC3.CCR6+.SI          1.41    0.95    0.62  ...   15.15    3.59    5.01   \n",
      "NK.27+11b-.BM          1.10    2.68    1.72  ...   10.42    2.10    1.46   \n",
      "\n",
      "                     512588  512589  512590  512591  512592  512593  512594  \n",
      "CellType                                                                     \n",
      "ILC2.SI               12.01    9.37    5.91    8.90    2.68    0.97    0.44  \n",
      "ILC3.NKp46-CCR6-.SI    2.85    5.25    4.59    5.36    4.14    1.36    0.57  \n",
      "ILC3.NKp46+.SI         9.75    4.40    8.75    6.68    4.70    1.40    0.75  \n",
      "ILC3.CCR6+.SI          6.89    3.86    7.61    9.16    4.81    1.58    2.04  \n",
      "NK.27+11b-.BM          1.72    1.72    6.33    4.82    2.48    1.72    2.48  \n",
      "\n",
      "[5 rows x 512595 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janna\\miniconda3\\envs\\data_analysis\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1162: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "perplexity must be less than n_samples",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m#tsne_em = TSNE(n_components = 2, perplexity = 30.0, early_exaggeration = 12, \u001b[39;00m\n\u001b[32m     45\u001b[39m  \u001b[38;5;66;03m#              n_iter = 1000, learning_rate = 368, verbose = 1).fit_transform(df_pc[:,0:49])\u001b[39;00m\n\u001b[32m     46\u001b[39m tsne = TSNE(n_components=\u001b[32m2\u001b[39m, perplexity=\u001b[32m50\u001b[39m, n_iter=\u001b[32m500\u001b[39m, learning_rate=\u001b[32m200\u001b[39m, verbose=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m tsne_result = \u001b[43mtsne\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_pc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m###questions so far: is it okay to reduce so radical to a sample of 5000? \u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m###and how many PCs used?\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m###and how optimize t-SNE parameters perplexicity and n_iter?\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m \u001b[38;5;66;03m#transpose > pca > sample > tsne > heirarchichal clusetr > color by color\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m#read me: look at hhow different papers do readmes\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbioinfokit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisuz\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\janna\\miniconda3\\envs\\data_analysis\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\janna\\miniconda3\\envs\\data_analysis\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1466\u001b[39m     estimator._validate_params()\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1469\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1470\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1471\u001b[39m     )\n\u001b[32m   1472\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\janna\\miniconda3\\envs\\data_analysis\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1175\u001b[39m, in \u001b[36mTSNE.fit_transform\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m   1172\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1173\u001b[39m     \u001b[38;5;28mself\u001b[39m._max_iter = \u001b[38;5;28mself\u001b[39m.max_iter\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1176\u001b[39m embedding = \u001b[38;5;28mself\u001b[39m._fit(X)\n\u001b[32m   1177\u001b[39m \u001b[38;5;28mself\u001b[39m.embedding_ = embedding\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\janna\\miniconda3\\envs\\data_analysis\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:864\u001b[39m, in \u001b[36mTSNE._check_params_vs_input\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    862\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    863\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.perplexity >= X.shape[\u001b[32m0\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mperplexity must be less than n_samples\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: perplexity must be less than n_samples"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import numpy as np\n",
    "data=pd.read_csv(\"data/ImmGenATAC18_AllOCRsInfo.csv\"\n",
    "                 )\n",
    "\n",
    "cols = [\"ILC2.SI\", \"ILC3.NKp46-CCR6-.SI\", \"ILC3.NKp46+.SI\", \"ILC3.CCR6+.SI\",\n",
    "        \"NK.27+11b-.BM\", \"NK.27+11b+.BM\", \"NK.27-11b+.BM\",\n",
    "        \"NK.27+11b-.Sp\", \"NK.27+11b+.Sp\", \"NK.27-11b+.Sp\"]\n",
    "subset = data[cols]\n",
    "\n",
    "# 3. Transponieren: Zelltypen werden zu Zeilen\n",
    "data_transposed = subset.T\n",
    "data_transposed.index.name = \"CellType\"\n",
    "\n",
    "# Jetzt kannst du mit `data_transposed` weiterarbeiten\n",
    "print(data_transposed.head())\n",
    "\n",
    "#data_sampled = data.sample(n=5000, random_state=42)\n",
    "#Daten standardisieren (z-Score pro OCR):\n",
    "#scaler = StandardScaler()\n",
    "#data_scaled = scaler.fit_transform(data_sampled)\n",
    "#data_scaled\n",
    "#PCA\n",
    "\n",
    "pca = PCA(n_components=25)\n",
    "pca_scores = PCA().fit_transform(data_transposed)\n",
    "# create a dataframe of pca_scores\n",
    "df_pc = pd.DataFrame(pca_scores)\n",
    "\n",
    "# create a dataframe of pca_scores\n",
    "df_pc = pd.DataFrame(pca_scores)\n",
    "df_pc\n",
    "\n",
    "# perform t-SNE on PCs scores\n",
    "# we will use first 50 PCs but this can vary\n",
    "from sklearn.manifold import TSNE\n",
    "#tsne_em = TSNE(n_components = 2, perplexity = 30.0, early_exaggeration = 12, \n",
    " #              n_iter = 1000, learning_rate = 368, verbose = 1).fit_transform(df_pc[:,0:49])\n",
    "tsne = TSNE(n_components=2, perplexity=50, n_iter=500, learning_rate=200, verbose=1)\n",
    "tsne_result = tsne.fit_transform(df_pc)\n",
    "\n",
    "###questions so far: is it okay to reduce so radical to a sample of 5000? \n",
    "###and how many PCs used?\n",
    "###and how optimize t-SNE parameters perplexicity and n_iter?\n",
    "###for visualization: does it look richt??? for eps>3 it is just a big blob, for <3 it is big blob and small dots???\n",
    "###also what for min_samples\n",
    "#transpose > pca > sample > tsne > heirarchichal clusetr > color by color\n",
    "#read me: look at hhow different papers do readmes\n",
    "from bioinfokit.visuz import cluster\n",
    "from sklearn.cluster import DBSCAN\n",
    "cluster.tsneplot(score=tsne_result, show=True)\n",
    "get_clusters = DBSCAN(eps = 1, min_samples = 10).fit_predict(tsne_result)\n",
    "print(set(get_clusters))\n",
    "\n",
    "cluster.tsneplot(score=tsne_result, colorlist=[str(i) for i in get_clusters], \n",
    "    colordot=('#713e5a', '#63a375', '#edc79b', '#d57a66', '#ca6680', '#395B50', '#92AFD7', '#b0413e', '#4381c1', '#736ced', '#631a86', '#de541e', '#022b3a', '#000000'), \n",
    "    legendpos='upper right', legendanchor=(1.15, 1), show=True)\n",
    "\n",
    "\n",
    "hierarchical_clustering = AgglomerativeClustering(n_clusters=10)  # Adjust n_clusters as needed\n",
    "cluster_labels = hierarchical_clustering.fit_predict(tsne_result)\n",
    "\n",
    "# Step 4: Visualize the t-SNE results with clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cluster in np.unique(cluster_labels):\n",
    "    plt.scatter(tsne_result[cluster_labels == cluster, 0],\n",
    "                tsne_result[cluster_labels == cluster, 1],\n",
    "                label=f'Cluster {cluster}')\n",
    "plt.title(\"t-SNE with Hierarchical Clustering\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# here eps parameter is very important and optimizing eps is essential\n",
    "# for well defined clusters. I have run DBSCAN with several eps values\n",
    "# and got good clusters with eps=3\n",
    "#get_clusters = DBSCAN(eps = 2, min_samples = 10).fit_predict(tsne_result)\n",
    "# check unique clusters\n",
    "# -1 value represents noisy points could not assigned to any cluster\n",
    "#set(get_clusters)\n",
    "#print(set(get_clusters))\n",
    "# get t-SNE plot with colors assigned to each cluster\n",
    "#transpose matrix!\n",
    "#leiden, k means: ists supposed to overlap, with matplotlib, splt,color by cell type and cluster\n",
    "#\n",
    "\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a407d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
